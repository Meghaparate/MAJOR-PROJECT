LARGE LANGUAGE MODEL BASED LEGAL TEXT SUMMARIZATION
 Abstract  —Legal  judgments  are  generally  very  long,  and 
 relevant  information  is  often  scattered  throughout  the  text. 
 Summarizing  a  legal  judgment  requires  capturing  crucial 
 details  comprehensively  from  the  lengthy  content. 
 Abstractive-summarization  models  based  on  pre-trained 
 language  often  encounter  limitations  in  handling  extended 
 input  texts.  Furthermore,  these  models  struggle  to  seamlessly 
 integrate  technical  terms  and  specific  topics  prevalent  in  legal 
 judgments.  In  this  paper,  a  new  dataset,  recently  developed 
 and  trained  on  Indian  supreme  court  case  documents,  was 
 utilized  to  maintain  relevance  and  capture  legal  nuances  in 
 the  summary.  OpenAI's  fine-tuned  GPT-3.5-turbo  model, 
 along  with  a  map-reduce  framework,  was  employed  to 
 overcome  token  limitations.  The  experimental  results 
 revealed  a  remarkable  improvement  in  rouge  scores 
 compared to existing models. 
 Index Terms  —GPT-3.5-turbo, Map-reduce, OpenAI 
